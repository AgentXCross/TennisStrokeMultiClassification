{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b554e9",
   "metadata": {},
   "source": [
    "# Tennis Stroke Classification: Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3807d5",
   "metadata": {},
   "source": [
    "### 0. Import PyTorch and Set Up Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e36ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c28313",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62463ecd",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing and Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walkthrough_data(dir_path):\n",
    "    \"\"\"Walk through dir_path returning its contents\"\"\"\n",
    "    for dir_path, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"{len(dirnames)} directories and {len(filenames)} images in {dir_path}\")\n",
    "\n",
    "walkthrough_data('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test path\n",
    "from pathlib import Path\n",
    "\n",
    "image_path = Path(\"dataset\")\n",
    "\n",
    "train_dir = image_path / \"train_set\"\n",
    "test_dir = image_path / \"test_set\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259d157",
   "metadata": {},
   "source": [
    "### 2. Visualize Images using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set seed\n",
    "random.seed(73)\n",
    "\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpeg\"))\n",
    "\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f'Image Class: {image_class}, Image Height: {img.height}, Image Width: {img.width}')\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image to array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image Class: {image_class}, Image Shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1253a92a",
   "metadata": {},
   "source": [
    "### 3. Transforming Data into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_square(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"Crops the center square from a PIL image.\"\"\"\n",
    "    width, height = img.size\n",
    "    min_dim = min(width, height)\n",
    "    left = (width - min_dim) // 2\n",
    "    top = (height - min_dim) // 2\n",
    "    right = left + min_dim\n",
    "    bottom = top + min_dim\n",
    "    return img.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomRotation(degrees = 15),\n",
    "    transforms.ColorJitter(brightness = 0.1, contrast = 0.1, saturation = 0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),     \n",
    "    transforms.Resize((320, 320)),            \n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bf250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths: list, transform, seed = 73, n = 3):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k = n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(nrows = 1, ncols = 2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
    "            ax[0].axis(False)\n",
    "\n",
    "            # Transform and plot image\n",
    "            transformed_image = transform(f).permute(1, 2, 0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed Image\\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(False)\n",
    "\n",
    "            fig.suptitle(f\"Class Name: {image_path.parent.stem}\", fontsize = 16)\n",
    "\n",
    "plot_transformed_images(image_paths = image_path_list, transform = train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a850",
   "metadata": {},
   "source": [
    "### 4. Loading image data using `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ade8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(\n",
    "    root = train_dir,\n",
    "    transform = train_transform,\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root = test_dir,\n",
    "    transform = test_transform,\n",
    ")\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc55dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82885ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace42162",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cda94",
   "metadata": {},
   "source": [
    "### 5. Turn loaded images into `DataLoader`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn train and test data into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = os.cpu_count(),\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = os.cpu_count(),\n",
    "    shuffle = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfac24",
   "metadata": {},
   "source": [
    "### 6. Creating a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Class Definition\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TennisStrokeClassification(nn.Module):\n",
    "    '''\n",
    "    Tennis Stroke Multiclass Classification Convolutional Neural Network (CNN) (Based on VGG Model).\n",
    "    Takes `num_classes` as input. Takes RGB inputs, thus 3 in_channels on first convolutional layer. \n",
    "    Each block of `self.features` applies `nn.Conv2d()` filters, normalizes batches using `nn.BatchNorm2d()`,\n",
    "    applies a rectified linear unit activation layer `nn.ReLU()`, and performs max pooling at the end using `nn.MaxPool2d()`.\n",
    "    Finally, `self.classifier` flattens the image and applies a linear layers with 512 * 4 * 4 inputs to `num_classes` outputs.\n",
    "    '''\n",
    "    def __init__(self, num_classes: int = 4):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # [32, 3, 224, 224]\n",
    "            nn.Conv2d(3, 64, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),  \n",
    "\n",
    "            # [32, 64, 112, 112]\n",
    "            nn.Conv2d(64, 128, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),  \n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            # [32, 128, 56, 56]\n",
    "            nn.Conv2d(128, 256, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size = 3, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            # [32, 256, 28, 28]\n",
    "        )\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        # [32, 256, 4, 4]\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p = 0.4),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the CNN model.\"\"\"\n",
    "        x = self.features(x)\n",
    "        if x.device.type == \"mps\":\n",
    "            x = x.cpu() # move to CPU for adaptive pooling\n",
    "            x = self.adaptive_pool(x)  \n",
    "            x = x.to(\"mps\") # move back to MPS\n",
    "        else:\n",
    "            x = self.adaptive_pool(x) # apply adaptive avg pool normally\n",
    "        x = self.classifier(x)    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_stroke_model = TennisStrokeClassification()\n",
    "tennis_stroke_model = tennis_stroke_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa9ac2",
   "metadata": {},
   "source": [
    "### 7. Creating Training and Testing Loop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "adam_optimizer = torch.optim.Adam(params = tennis_stroke_model.parameters(), lr = 0.0001, weight_decay = 1e-4)\n",
    "\n",
    "scheduler = StepLR(\n",
    "    adam_optimizer,  \n",
    "    step_size = 5,  \n",
    "    gamma = 0.5    \n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy_fn(pred, true):\n",
    "    correct = torch.eq(pred, true).sum().item()\n",
    "    return correct / len(pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e54579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_step() takes the training dataloader, test_step() takes the testing dataloader\n",
    "def train_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        seed: int, \n",
    "        loss_function: torch.nn.Module,\n",
    "        optimization_function: torch.optim.Optimizer,\n",
    "        accuracy_function,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    train_loss_total, train_acc_total = 0, 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Move to best device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_train_preds_logits = model(X_batch)\n",
    "        # Loss\n",
    "        loss = loss_function(y_train_preds_logits, y_batch)\n",
    "        train_loss_total += loss.item()\n",
    "        # Backpropagation\n",
    "        optimization_function.zero_grad()\n",
    "        loss.backward()\n",
    "        # Gradient Descent\n",
    "        optimization_function.step()\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_function(y_train_preds_logits.argmax(dim = 1), y_batch)\n",
    "        train_acc_total += accuracy\n",
    "    train_acc = train_acc_total / len(dataloader)\n",
    "    train_loss = train_loss_total / len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss} | Train Accuracy: {train_acc}\")\n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        loss_function: torch.nn.Module,\n",
    "        seed: int,\n",
    "        accuracy_function,\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    test_loss_total, test_accuracy_total = 0, 0\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # Forward pass\n",
    "            y_test_preds_logits = model(X_batch)\n",
    "            # Loss\n",
    "            loss = loss_function(y_test_preds_logits, y_batch)\n",
    "            test_loss_total += loss.item()\n",
    "            # Accuracy\n",
    "            accuracy = accuracy_function(y_test_preds_logits.argmax(dim = 1), y_batch)\n",
    "            test_accuracy_total += accuracy\n",
    "        test_acc = test_accuracy_total / len(dataloader)\n",
    "        test_loss = test_loss_total / len(dataloader)\n",
    "        print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the test loop inside a function\n",
    "def train_test_loop(\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int,\n",
    "        device,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduling_function: torch.optim.lr_scheduler,\n",
    "        loss_function: torch.nn.Module\n",
    "):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch} ==============================\")\n",
    "        train_step(\n",
    "            model = model,\n",
    "            dataloader = train_dataloader,\n",
    "            seed = 73,\n",
    "            loss_function = loss_function,\n",
    "            optimization_function = optimizer,\n",
    "            accuracy_function = accuracy_fn,\n",
    "        )\n",
    "        test_step(\n",
    "            model = model,\n",
    "            loss_function = loss_function,\n",
    "            seed = 73,\n",
    "            accuracy_function = accuracy_fn,\n",
    "            dataloader = test_dataloader\n",
    "        )\n",
    "        scheduling_function.step()\n",
    "\n",
    "train_test_loop(model = tennis_stroke_model, epochs = 5, device = device, optimizer = adam_optimizer, scheduling_function = scheduler, loss_function = loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
