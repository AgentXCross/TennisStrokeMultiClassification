{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62df9e9e",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6127c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "image_path = Path(\"dataset\")\n",
    "\n",
    "train_dir = image_path / \"train_set\"\n",
    "test_dir = image_path / \"test_set\"\n",
    "\n",
    "def center_crop_square(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"Crops the center square from a PIL image.\"\"\"\n",
    "    width, height = img.size\n",
    "    min_dim = min(width, height)\n",
    "    left = (width - min_dim) // 2\n",
    "    top = (height - min_dim) // 2\n",
    "    right = left + min_dim\n",
    "    bottom = top + min_dim\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomRotation(degrees = 15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),     \n",
    "    transforms.Resize((320, 320)),            \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root = train_dir,\n",
    "    transform = train_transform,\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root = test_dir,\n",
    "    transform = test_transform,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b938fa2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48444af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional path\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "        # Shortcut path (identity/nothing or 1x1 conv to match shapes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out += self.shortcut(x)   # skip connection\n",
    "        out = self.relu(out)      # apply ReLU() after the shortcut\n",
    "        return out\n",
    "    \n",
    "class TennisStrokeClassifier(nn.Module):\n",
    "    def __init__(self, num_classes = 4):\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvResidualBlock(in_channels = 3, out_channels = 64)\n",
    "        self.layer2 = ConvResidualBlock(in_channels = 64, out_channels = 128, stride = 2)\n",
    "        self.layer3 = ConvResidualBlock(in_channels = 128, out_channels = 256, stride = 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494388c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_stroke_model = TennisStrokeClassifier()\n",
    "tennis_stroke_model = tennis_stroke_model.to(device)\n",
    "\n",
    "sgd_optimizer = torch.optim.SGD(params = tennis_stroke_model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 1e-4)\n",
    "\n",
    "sgd_scheduler = StepLR(\n",
    "    sgd_optimizer,  \n",
    "    step_size = 5,  \n",
    "    gamma = 0.5    \n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy_fn(pred, true):\n",
    "    correct = torch.eq(pred, true).sum().item()\n",
    "    return correct / len(pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324f1b3",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143f2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        seed: int, \n",
    "        loss_function: torch.nn.Module,\n",
    "        optimization_function: torch.optim.Optimizer,\n",
    "        accuracy_function,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    train_loss_total, train_acc_total = 0, 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Move to best device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_train_preds_logits = model(X_batch)\n",
    "        # Loss\n",
    "        loss = loss_function(y_train_preds_logits, y_batch)\n",
    "        train_loss_total += loss.item()\n",
    "        # Backpropagation\n",
    "        optimization_function.zero_grad()\n",
    "        loss.backward()\n",
    "        # Gradient Descent\n",
    "        optimization_function.step()\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_function(y_train_preds_logits.argmax(dim = 1), y_batch)\n",
    "        train_acc_total += accuracy\n",
    "    train_acc = train_acc_total / len(dataloader)\n",
    "    train_loss = train_loss_total / len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss} | Train Accuracy: {train_acc}\")\n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        loss_function: torch.nn.Module,\n",
    "        seed: int,\n",
    "        accuracy_function,\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    test_loss_total, test_accuracy_total = 0, 0\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # Forward pass\n",
    "            y_test_preds_logits = model(X_batch)\n",
    "            # Loss\n",
    "            loss = loss_function(y_test_preds_logits, y_batch)\n",
    "            test_loss_total += loss.item()\n",
    "            # Accuracy\n",
    "            accuracy = accuracy_function(y_test_preds_logits.argmax(dim = 1), y_batch)\n",
    "            test_accuracy_total += accuracy\n",
    "        test_acc = test_accuracy_total / len(dataloader)\n",
    "        test_loss = test_loss_total / len(dataloader)\n",
    "        print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc}\")\n",
    "\n",
    "def train_test_loop(\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int,\n",
    "        device,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduling_function: torch.optim.lr_scheduler,\n",
    "        loss_function: torch.nn.Module\n",
    "):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch} ==============================\")\n",
    "        train_step(\n",
    "            model = model,\n",
    "            dataloader = train_dataloader,\n",
    "            seed = 73,\n",
    "            loss_function = loss_function,\n",
    "            optimization_function = optimizer,\n",
    "            accuracy_function = accuracy_fn,\n",
    "        )\n",
    "        test_step(\n",
    "            model = model,\n",
    "            loss_function = loss_function,\n",
    "            seed = 73,\n",
    "            accuracy_function = accuracy_fn,\n",
    "            dataloader = test_dataloader\n",
    "        )\n",
    "        scheduling_function.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79f3ff",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc7513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ==============================\n",
      "Train Loss: 1.2900761106739873 | Train Accuracy: 38.24728260869565\n",
      "Test Loss: 1.2569628556569417 | Test Accuracy: 36.041666666666664\n",
      "Epoch: 1 ==============================\n",
      "Train Loss: 1.2248216737871584 | Train Accuracy: 41.91576086956522\n",
      "Test Loss: 1.216803824901581 | Test Accuracy: 38.958333333333336\n",
      "Epoch: 2 ==============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtennis_stroke_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduling_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mtrain_test_loop\u001b[39m\u001b[34m(model, epochs, device, optimizer, scheduling_function, loss_function)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ==============================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m73\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccuracy_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     test_step(\n\u001b[32m     78\u001b[39m         model = model,\n\u001b[32m     79\u001b[39m         loss_function = loss_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m         dataloader = test_dataloader\n\u001b[32m     83\u001b[39m     )\n\u001b[32m     84\u001b[39m     scheduling_function.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, seed, loss_function, optimization_function, accuracy_function)\u001b[39m\n\u001b[32m     24\u001b[39m     optimization_function.step()\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     accuracy = \u001b[43maccuracy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_preds_logits\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     train_acc_total += accuracy\n\u001b[32m     28\u001b[39m train_acc = train_acc_total / \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36maccuracy_fn\u001b[39m\u001b[34m(pred, true)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccuracy_fn\u001b[39m(pred, true):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     correct = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m correct / \u001b[38;5;28mlen\u001b[39m(pred) * \u001b[32m100\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_test_loop(model = tennis_stroke_model, epochs = 5, device = device, optimizer = sgd_optimizer, scheduling_function = sgd_scheduler, loss_function = loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
