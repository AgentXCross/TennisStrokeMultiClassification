{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62df9e9e",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba6127c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "image_path = Path(\"dataset\")\n",
    "\n",
    "train_dir = image_path / \"train_set\"\n",
    "test_dir = image_path / \"test_set\"\n",
    "\n",
    "def center_crop_square(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"Crops the center square from a PIL image.\"\"\"\n",
    "    width, height = img.size\n",
    "    min_dim = min(width, height)\n",
    "    left = (width - min_dim) // 2\n",
    "    top = (height - min_dim) // 2\n",
    "    right = left + min_dim\n",
    "    bottom = top + min_dim\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),\n",
    "    transforms.Resize((320, 320)),\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomRotation(degrees = 15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(center_crop_square),     \n",
    "    transforms.Resize((320, 320)),            \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root = train_dir,\n",
    "    transform = train_transform,\n",
    "    target_transform = None\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root = test_dir,\n",
    "    transform = test_transform,\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = False,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b938fa2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48444af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional path\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "        # Shortcut path (identity/nothing or 1x1 conv to match shapes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_layers(x)\n",
    "        out += self.shortcut(x)   # skip connection\n",
    "        out = self.relu(out)      # apply ReLU() after the shortcut\n",
    "        return out\n",
    "    \n",
    "class TennisStrokeClassifier(nn.Module):\n",
    "    def __init__(self, num_classes = 4):\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvResidualBlock(in_channels = 3, out_channels = 64)\n",
    "        self.layer2 = ConvResidualBlock(in_channels = 64, out_channels = 128, stride = 2)\n",
    "        self.layer3 = ConvResidualBlock(in_channels = 128, out_channels = 256, stride = 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494388c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tennis_stroke_model = TennisStrokeClassifier()\n",
    "tennis_stroke_model = tennis_stroke_model.to(device)\n",
    "\n",
    "sgd_optimizer = torch.optim.SGD(params = tennis_stroke_model.parameters(), lr = 0.01, momentum = 0.9, weight_decay = 1e-4)\n",
    "\n",
    "sgd_scheduler = StepLR(\n",
    "    sgd_optimizer,  \n",
    "    step_size = 5,  \n",
    "    gamma = 0.5    \n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy_fn(pred, true):\n",
    "    correct = torch.eq(pred, true).sum().item()\n",
    "    return correct / len(pred) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324f1b3",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143f2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "        model: torch.nn.Module,\n",
    "        dataloader: torch.utils.data.DataLoader,\n",
    "        seed: int, \n",
    "        loss_function: torch.nn.Module,\n",
    "        optimization_function: torch.optim.Optimizer,\n",
    "        accuracy_function,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    train_loss_total, train_acc_total = 0, 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        # Move to best device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        model.train()\n",
    "        # Forward pass\n",
    "        y_train_preds_logits = model(X_batch)\n",
    "        # Loss\n",
    "        loss = loss_function(y_train_preds_logits, y_batch)\n",
    "        train_loss_total += loss.item()\n",
    "        # Backpropagation\n",
    "        optimization_function.zero_grad()\n",
    "        loss.backward()\n",
    "        # Gradient Descent\n",
    "        optimization_function.step()\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_function(y_train_preds_logits.argmax(dim = 1), y_batch)\n",
    "        train_acc_total += accuracy\n",
    "    train_acc = train_acc_total / len(dataloader)\n",
    "    train_loss = train_loss_total / len(dataloader)\n",
    "    print(f\"Train Loss: {train_loss} | Train Accuracy: {train_acc}\")\n",
    "\n",
    "def test_step(\n",
    "        model: torch.nn.Module,\n",
    "        loss_function: torch.nn.Module,\n",
    "        seed: int,\n",
    "        accuracy_function,\n",
    "        dataloader: torch.utils.data.DataLoader\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "    test_loss_total, test_accuracy_total = 0, 0\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            # Forward pass\n",
    "            y_test_preds_logits = model(X_batch)\n",
    "            # Loss\n",
    "            loss = loss_function(y_test_preds_logits, y_batch)\n",
    "            test_loss_total += loss.item()\n",
    "            # Accuracy\n",
    "            accuracy = accuracy_function(y_test_preds_logits.argmax(dim = 1), y_batch)\n",
    "            test_accuracy_total += accuracy\n",
    "        test_acc = test_accuracy_total / len(dataloader)\n",
    "        test_loss = test_loss_total / len(dataloader)\n",
    "        print(f\"Test Loss: {test_loss} | Test Accuracy: {test_acc}\")\n",
    "\n",
    "def train_test_loop(\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int,\n",
    "        device,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        scheduling_function: torch.optim.lr_scheduler,\n",
    "        loss_function: torch.nn.Module\n",
    "):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch} ==============================\")\n",
    "        train_step(\n",
    "            model = model,\n",
    "            dataloader = train_dataloader,\n",
    "            seed = 73,\n",
    "            loss_function = loss_function,\n",
    "            optimization_function = optimizer,\n",
    "            accuracy_function = accuracy_fn,\n",
    "        )\n",
    "        test_step(\n",
    "            model = model,\n",
    "            loss_function = loss_function,\n",
    "            seed = 73,\n",
    "            accuracy_function = accuracy_fn,\n",
    "            dataloader = test_dataloader\n",
    "        )\n",
    "        scheduling_function.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a79f3ff",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbc7513e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 ==============================\n",
      "Train Loss: 1.2852159686710523 | Train Accuracy: 37.97554347826087\n",
      "Test Loss: 1.235659846663475 | Test Accuracy: 35.416666666666664\n",
      "Epoch: 1 ==============================\n",
      "Train Loss: 1.2196418681870336 | Train Accuracy: 41.71195652173913\n",
      "Test Loss: 1.2449156753718853 | Test Accuracy: 41.25\n",
      "Epoch: 2 ==============================\n",
      "Train Loss: 1.1709506265495135 | Train Accuracy: 44.22554347826087\n",
      "Test Loss: 1.1747179809957742 | Test Accuracy: 36.875\n",
      "Epoch: 3 ==============================\n",
      "Train Loss: 1.1529144048690796 | Train Accuracy: 44.49728260869565\n",
      "Test Loss: 1.440933978309234 | Test Accuracy: 39.583333333333336\n",
      "Epoch: 4 ==============================\n",
      "Train Loss: 1.1368577972702358 | Train Accuracy: 45.85597826086956\n",
      "Test Loss: 1.159144600853324 | Test Accuracy: 39.375\n",
      "Epoch: 5 ==============================\n",
      "Train Loss: 1.0930090948291447 | Train Accuracy: 48.77717391304348\n",
      "Test Loss: 1.0799746641889214 | Test Accuracy: 48.75\n",
      "Epoch: 6 ==============================\n",
      "Train Loss: 1.0782781722752943 | Train Accuracy: 49.18478260869565\n",
      "Test Loss: 1.0908863328397274 | Test Accuracy: 40.208333333333336\n",
      "Epoch: 7 ==============================\n",
      "Train Loss: 1.0738156360128652 | Train Accuracy: 48.91304347826087\n",
      "Test Loss: 1.0989935209353765 | Test Accuracy: 38.75\n",
      "Epoch: 8 ==============================\n",
      "Train Loss: 1.0632847158805183 | Train Accuracy: 50.203804347826086\n",
      "Test Loss: 1.0836301588763793 | Test Accuracy: 40.416666666666664\n",
      "Epoch: 9 ==============================\n",
      "Train Loss: 1.0521291079728499 | Train Accuracy: 50.81521739130435\n",
      "Test Loss: 1.069884667918086 | Test Accuracy: 39.166666666666664\n",
      "Epoch: 10 ==============================\n",
      "Train Loss: 1.016013714282409 | Train Accuracy: 52.98913043478261\n",
      "Test Loss: 1.009969380746285 | Test Accuracy: 56.041666666666664\n",
      "Epoch: 11 ==============================\n",
      "Train Loss: 0.9975862580796947 | Train Accuracy: 53.87228260869565\n",
      "Test Loss: 0.9958583299691478 | Test Accuracy: 57.083333333333336\n",
      "Epoch: 12 ==============================\n",
      "Train Loss: 0.9904943549114725 | Train Accuracy: 55.02717391304348\n",
      "Test Loss: 0.994356190164884 | Test Accuracy: 56.25\n",
      "Epoch: 13 ==============================\n",
      "Train Loss: 0.9837487702784331 | Train Accuracy: 55.50271739130435\n",
      "Test Loss: 0.9985214550048113 | Test Accuracy: 56.041666666666664\n",
      "Epoch: 14 ==============================\n",
      "Train Loss: 0.977752457494321 | Train Accuracy: 55.97826086956522\n",
      "Test Loss: 0.9951937538882096 | Test Accuracy: 56.458333333333336\n",
      "Epoch: 15 ==============================\n",
      "Train Loss: 0.9514706134796143 | Train Accuracy: 58.83152173913044\n",
      "Test Loss: 0.9541353806853294 | Test Accuracy: 60.833333333333336\n",
      "Epoch: 16 ==============================\n",
      "Train Loss: 0.9411965712257053 | Train Accuracy: 59.442934782608695\n",
      "Test Loss: 0.9556197545180718 | Test Accuracy: 60.625\n",
      "Epoch: 17 ==============================\n",
      "Train Loss: 0.9364959519842396 | Train Accuracy: 59.85054347826087\n",
      "Test Loss: 0.9541493519519766 | Test Accuracy: 60.625\n",
      "Epoch: 18 ==============================\n",
      "Train Loss: 0.9314351587191873 | Train Accuracy: 60.12228260869565\n",
      "Test Loss: 0.9563559737056494 | Test Accuracy: 60.416666666666664\n",
      "Epoch: 19 ==============================\n",
      "Train Loss: 0.9263787684233292 | Train Accuracy: 60.46195652173913\n",
      "Test Loss: 0.9587220596770446 | Test Accuracy: 61.041666666666664\n",
      "Epoch: 20 ==============================\n",
      "Train Loss: 0.9106208448824675 | Train Accuracy: 60.66576086956522\n",
      "Test Loss: 0.9295121545592944 | Test Accuracy: 59.791666666666664\n",
      "Epoch: 21 ==============================\n",
      "Train Loss: 0.9029224618621494 | Train Accuracy: 60.869565217391305\n",
      "Test Loss: 0.9308584647874037 | Test Accuracy: 58.333333333333336\n",
      "Epoch: 22 ==============================\n",
      "Train Loss: 0.8989859573219133 | Train Accuracy: 61.27717391304348\n",
      "Test Loss: 0.929440168167154 | Test Accuracy: 58.125\n",
      "Epoch: 23 ==============================\n",
      "Train Loss: 0.8952608782312145 | Train Accuracy: 61.41304347826087\n",
      "Test Loss: 0.9290875141819318 | Test Accuracy: 58.125\n",
      "Epoch: 24 ==============================\n",
      "Train Loss: 0.8917574688144352 | Train Accuracy: 61.27717391304348\n",
      "Test Loss: 0.92842210115244 | Test Accuracy: 58.125\n",
      "Epoch: 25 ==============================\n",
      "Train Loss: 0.8788396236689194 | Train Accuracy: 62.77173913043478\n",
      "Test Loss: 0.8947815001010895 | Test Accuracy: 63.75\n",
      "Epoch: 26 ==============================\n",
      "Train Loss: 0.8746345444865848 | Train Accuracy: 62.90760869565217\n",
      "Test Loss: 0.8935125155374408 | Test Accuracy: 63.75\n",
      "Epoch: 27 ==============================\n",
      "Train Loss: 0.872022508279137 | Train Accuracy: 62.97554347826087\n",
      "Test Loss: 0.8917759295552969 | Test Accuracy: 63.75\n",
      "Epoch: 28 ==============================\n",
      "Train Loss: 0.8691999212555264 | Train Accuracy: 63.17934782608695\n",
      "Test Loss: 0.8896915078163147 | Test Accuracy: 63.75\n",
      "Epoch: 29 ==============================\n",
      "Train Loss: 0.8665559278882068 | Train Accuracy: 63.24728260869565\n",
      "Test Loss: 0.8882801764955123 | Test Accuracy: 64.16666666666667\n",
      "Epoch: 30 ==============================\n",
      "Train Loss: 0.8581785080225571 | Train Accuracy: 64.1304347826087\n",
      "Test Loss: 0.874933401060601 | Test Accuracy: 66.25\n",
      "Epoch: 31 ==============================\n",
      "Train Loss: 0.8531474380389504 | Train Accuracy: 64.1304347826087\n",
      "Test Loss: 0.8737956597159307 | Test Accuracy: 65.41666666666667\n",
      "Epoch: 32 ==============================\n",
      "Train Loss: 0.8512941508189492 | Train Accuracy: 64.47010869565217\n",
      "Test Loss: 0.8725811634833615 | Test Accuracy: 65.0\n",
      "Epoch: 33 ==============================\n",
      "Train Loss: 0.849654179552327 | Train Accuracy: 64.2663043478261\n",
      "Test Loss: 0.8713116506735484 | Test Accuracy: 65.20833333333333\n",
      "Epoch: 34 ==============================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_test_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtennis_stroke_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduling_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msgd_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mtrain_test_loop\u001b[39m\u001b[34m(model, epochs, device, optimizer, scheduling_function, loss_function)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ==============================\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m73\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimization_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccuracy_function\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     test_step(\n\u001b[32m     78\u001b[39m         model = model,\n\u001b[32m     79\u001b[39m         loss_function = loss_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m         dataloader = test_dataloader\n\u001b[32m     83\u001b[39m     )\n\u001b[32m     84\u001b[39m     scheduling_function.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, seed, loss_function, optimization_function, accuracy_function)\u001b[39m\n\u001b[32m     24\u001b[39m     optimization_function.step()\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     accuracy = \u001b[43maccuracy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train_preds_logits\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     train_acc_total += accuracy\n\u001b[32m     28\u001b[39m train_acc = train_acc_total / \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36maccuracy_fn\u001b[39m\u001b[34m(pred, true)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maccuracy_fn\u001b[39m(pred, true):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     correct = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m correct / \u001b[38;5;28mlen\u001b[39m(pred) * \u001b[32m100\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_test_loop(model = tennis_stroke_model, epochs = 50, device = device, optimizer = sgd_optimizer, scheduling_function = sgd_scheduler, loss_function = loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7344b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "torch.mps.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.active_children() \n",
    "for p in mp.active_children():\n",
    "    p.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
